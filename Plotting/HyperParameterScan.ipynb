{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Depth_3/Width_50/BatchSize_1024/LearningRate0.005\n",
      "Depth_3/Width_50/BatchSize_1024/LearningRate0.001\n",
      "Depth_3/Width_50/BatchSize_256/LearningRate0.005\n",
      "Depth_3/Width_50/BatchSize_2048/LearningRate0.001\n",
      "Depth_3/Width_50/BatchSize_2048/LearningRate0.0001\n",
      "Depth_3/Width_100/BatchSize_256/LearningRate0.0001\n",
      "Depth_3/Width_50/BatchSize_256/LearningRate0.0005\n",
      "Depth_3/Width_50/BatchSize_256/LearningRate0.001\n",
      "Depth_3/Width_50/BatchSize_512/LearningRate0.005\n",
      "Depth_3/Width_50/BatchSize_512/LearningRate0.0001\n",
      "Depth_3/Width_50/BatchSize_256/LearningRate0.0001\n",
      "Depth_3/Width_50/BatchSize_512/LearningRate0.001\n",
      "Depth_3/Width_50/BatchSize_1024/LearningRate0.0001\n",
      "Depth_3/Width_50/BatchSize_1024/LearningRate0.0005\n",
      "Depth_3/Width_50/BatchSize_512/LearningRate0.0005\n",
      "Depth_3/Width_100/BatchSize_256/LearningRate0.0005\n",
      "Depth_3/Width_50/BatchSize_2048/LearningRate0.0005\n",
      "Depth_3/Width_50/BatchSize_2048/LearningRate0.005\n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/global/u1/b/badea/aleph/unfold-ee-logtau/results/training-8ba722ad/*/model_weights*\"\n",
    "file_pattern = os.path.join(base_path, \"*iter*_step*.pkl\")\n",
    "\n",
    "# Glob for all matching files\n",
    "file_names = glob.glob(file_pattern)\n",
    "# Sort the file names by iteration number and step number\n",
    "file_names.sort(key=lambda x: (int(os.path.basename(x).split('_')[-2].replace('iter', '')), \n",
    "                               int(os.path.basename(x).split('_')[-1].replace('step', '').replace('.pkl', ''))))\n",
    "# only do step 1\n",
    "file_names = [i for i in file_names if \"step1\" in i]\n",
    "print(len(file_names))\n",
    "\n",
    "# losses dictionary\n",
    "losses = {}\n",
    "\n",
    "# Loop over all found files\n",
    "for file_name in file_names:\n",
    "\n",
    "    # load the configuration file\n",
    "    config_file = os.path.join(os.path.dirname(file_name), \"conf.json\")\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Load the loss file\n",
    "    with open(file_name, 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "    train_loss = temp['loss']\n",
    "    val_loss = temp['val_loss']\n",
    "\n",
    "    key = f\"Depth_{len(config['layer_sizes'])}/Width_{config['layer_sizes'][0]}/BatchSize_{config['batch_size']}/LearningRate{config['lr']}\"\n",
    "    losses[key] = [train_loss, val_loss]\n",
    "    print(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss\n",
      "  Lowest:  ['Depth_3/Width_50/BatchSize_256/LearningRate0.0001', 0.60254794]\n",
      "  Highest:  ['Depth_3/Width_50/BatchSize_2048/LearningRate0.0001', 0.6028908]\n",
      "  Median:  0.6026608\n",
      "  Mean:  0.60268426\n",
      "  Std:  0.000101635196\n",
      "validation loss\n",
      "  Lowest:  ['Depth_3/Width_50/BatchSize_2048/LearningRate0.0001', 0.60205704]\n",
      "  Highest:  ['Depth_3/Width_50/BatchSize_512/LearningRate0.005', 0.60318583]\n",
      "  Median:  0.602778\n",
      "  Mean:  0.6027052\n",
      "  Std:  0.0003390444\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate([\"training loss\", \"validation loss\"]):\n",
    "    print(name)\n",
    "    temp = [[key, val[i][-1]] for key, val in losses.items()]\n",
    "    temp.sort(key=lambda x: x[1])\n",
    "    print(\"  Lowest: \", temp[0])\n",
    "    print(\"  Highest: \", temp[-1])\n",
    "    print(\"  Median: \", np.median([i[1] for i in temp]))\n",
    "    print(\"  Mean: \", np.mean([i[1] for i in temp]))\n",
    "    print(\"  Std: \", np.std([i[1] for i in temp]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifoldVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
